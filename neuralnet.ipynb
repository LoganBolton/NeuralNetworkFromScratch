{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "73da0f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "11d4c083-0801-48a8-ba8c-0f57ed4a1093",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ubyte_file(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        # Read the magic number\n",
    "        magic_number = int.from_bytes(f.read(4), 'big')\n",
    "        \n",
    "        if magic_number == 2051:  # Magic number for images\n",
    "            num_images = int.from_bytes(f.read(4), 'big')\n",
    "            rows = int.from_bytes(f.read(4), 'big')\n",
    "            cols = int.from_bytes(f.read(4), 'big')\n",
    "            images = np.frombuffer(f.read(), dtype=np.uint8).reshape(num_images, rows, cols)\n",
    "            return images\n",
    "        \n",
    "        elif magic_number == 2049:  # Magic number for labels\n",
    "            num_labels = int.from_bytes(f.read(4), 'big')\n",
    "            labels = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "            return labels\n",
    "        \n",
    "        else:\n",
    "            raise ValueError('Invalid magic number in file header')\n",
    "\n",
    "train_images_path = './data/train-images-idx3-ubyte'\n",
    "train_labels_path = './data/train-labels-idx1-ubyte'\n",
    "\n",
    "train_images = read_ubyte_file(train_images_path)\n",
    "train_labels = read_ubyte_file(train_labels_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c4909754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(train_labels.shape)\n",
    "print(train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8fb97853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape)\n",
    "# go from (60000, 28, 28) to (60000, 784)\n",
    "X = train_images.reshape(train_images.shape[0],train_images.shape[1]*train_images.shape[2])\n",
    "print(train_images.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "787dfe4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params():\n",
    "    # each pixel from image needs to point to 10 hidden neurons\n",
    "    W1 = np.random.randn(784, 10) * 0.01 \n",
    "    #1 bias for each of the 10 hidden neurons\n",
    "    b1 = np.random.randn(1, 10) * 0.01   \n",
    "    \n",
    "    # each of the 10 hidden neurons needs to point to each of the 10 output neurons\n",
    "    W2 = np.random.randn(10, 10) * 0.01  \n",
    "    # 1 bias for each of the 10 output neurons\n",
    "    b2 = np.random.randn(1, 10) * 0.01   \n",
    "    \n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "81f61cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(x):\n",
    "    return np.maximum(0, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0c0c1ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_max(Z):\n",
    "    exp_Z = np.exp(Z - np.max(Z, axis=1, keepdims=True))  # Subtract max for numerical stability\n",
    "    return exp_Z / np.sum(exp_Z, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "afe0c7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(labels, num_classes):\n",
    "    # Initialize a matrix of zeros with shape (number of labels, number of classes)\n",
    "    one_hot = np.zeros((labels.size, num_classes))\n",
    "    \n",
    "    # Set the corresponding index to 1 for each label\n",
    "    one_hot[np.arange(labels.size), labels] = 1\n",
    "    \n",
    "    return one_hot\n",
    "\n",
    "Y = one_hot_encode(train_labels, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f91b00ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(A2, Y):\n",
    "    m = Y.shape[0]\n",
    "    Y_int = np.argmax(Y, axis=1)\n",
    "\n",
    "    log_probs = -np.log(A2[np.arange(m), Y_int])\n",
    "    loss = np.sum(log_probs) / m\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "94150ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(X, W1, b1, W2, b2, Y):\n",
    "    Z1 = np.dot(X, W1) + b1\n",
    "    A1 = ReLU(Z1)\n",
    "    Z2 = np.dot(A1, W2) + b2\n",
    "    A2 = soft_max(Z2)\n",
    "    return Z1, A1, Z2, A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "aa76a96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_prop(X, Y, Z1, A1, Z2, A2, W1, W2, b1, b2, learning_rate):\n",
    "    # used to find the normalized gradient\n",
    "    # m = num of training examples in batch\n",
    "    m = X.shape[0]\n",
    "    dZ2 = A2 - Y\n",
    "    \n",
    "    # multiply the output of h1 by the change in the output\n",
    "    dW2 = np.dot(A1.T, dZ2) / m\n",
    "    db2 = np.sum(dZ2, axis=0, keepdims=True) / m\n",
    "    \n",
    "    dA = np.dot(dZ2, W2.T)\n",
    "    \n",
    "    # relu derivative\n",
    "    dZ1 = dA * (Z1 > 0)\n",
    "    \n",
    "    dW1 = np.dot(X.T, dZ1) / m\n",
    "    db1 = np.sum(dZ1, axis=0, keepdims=True) / m\n",
    "    \n",
    "    return dW1, db1, dW2, db2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "24a2a959",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, learning_rate):\n",
    "    W1 -= learning_rate * dW1\n",
    "    b1 -= learning_rate * db1\n",
    "    W2 -= learning_rate * dW2\n",
    "    b2 -= learning_rate * db2\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a173f86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, Y, W1, b1, W2, b2, learning_rate, epochs):\n",
    "    for i in range(epochs):\n",
    "        # forward\n",
    "        Z1, A1, Z2, A2 = forward(X, W1, b1, W2, b2, Y)\n",
    "        loss = compute_loss(A2, Y)\n",
    "        #backward\n",
    "        dW1, db1, dW2, db2 = back_prop(X, Y, Z1, A1, Z2, A2, W1, W2, b1, b2, learning_rate)\n",
    "        \n",
    "        W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, learning_rate)\n",
    "\n",
    "        if i % 50 == 0:\n",
    "            print(f'Epoch {i}: loss = {loss}')\n",
    "    return W1, b1, W2, b2\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "217b2fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "W1, b1, W2, b2 = init_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cf89790d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss = 2.46007841812123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kp/vdv61pd97vd0x29b257r8h7h0000gn/T/ipykernel_49413/1970519496.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  log_probs = -np.log(A2[np.arange(m), Y_int])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: loss = 2.3025102031449123\n",
      "Epoch 100: loss = 2.3016480478923356\n",
      "Epoch 150: loss = 2.301335549158335\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[86], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m W1, b1, W2, b2 \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[84], line 7\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(X, Y, W1, b1, W2, b2, learning_rate, epochs)\u001b[0m\n\u001b[1;32m      5\u001b[0m loss \u001b[38;5;241m=\u001b[39m compute_loss(A2, Y)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#backward\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m dW1, db1, dW2, db2 \u001b[38;5;241m=\u001b[39m \u001b[43mback_prop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mZ1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mZ2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m W1, b1, W2, b2 \u001b[38;5;241m=\u001b[39m update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, learning_rate)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m50\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[0;32mIn[82], line 16\u001b[0m, in \u001b[0;36mback_prop\u001b[0;34m(X, Y, Z1, A1, Z2, A2, W1, W2, b1, b2, learning_rate)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# relu derivative\u001b[39;00m\n\u001b[1;32m     14\u001b[0m dZ1 \u001b[38;5;241m=\u001b[39m dA \u001b[38;5;241m*\u001b[39m (Z1 \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m dW1 \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdZ1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m m\n\u001b[1;32m     17\u001b[0m db1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(dZ1, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m/\u001b[39m m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dW1, db1, dW2, db2\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "W1, b1, W2, b2 = train(X, Y, W1, b1, W2, b2, 0.1, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6ac9cc88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.11237%\n"
     ]
    }
   ],
   "source": [
    "def get_predictions(A2):\n",
    "    return np.argmax(A2, axis=1)\n",
    "\n",
    "def get_accuracy(predictions, Y):\n",
    "    # Convert one-hot encoded Y to integer labels\n",
    "    Y_int = np.argmax(Y, axis=1)\n",
    "    return np.sum(predictions == Y_int) / Y_int.size\n",
    "\n",
    "#returns A2\n",
    "_, _, _, A2 = forward(X, W1, b1, W2, b2, Y)\n",
    "\n",
    "# Get predictions from the output layer activations\n",
    "predictions = get_predictions(A2)\n",
    "\n",
    "# Calculate and print the accuracy\n",
    "accuracy = get_accuracy(predictions, Y)\n",
    "print(f'Accuracy: {accuracy:.5f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
